{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, RocCurveDisplay, make_scorer\n",
    "from sklearn.model_selection import learning_curve\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_transformed = pd.read_csv('new_data/clean-data_without_outliers.csv')\n",
    "#competition_transformed = pd.read_csv('new_data/clean-comp.csv')\n",
    "data = pd.read_csv('new_data/clean-data_without_outliers.csv')\n",
    "competition = pd.read_csv('new_data/clean-comp.csv')\n",
    "#data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['playerID', 'year', 'stint', 'tmID', 'GP', 'oRebounds', 'dRebounds',\n",
       "       'dq', 'PostMinutes', 'PostPoints', 'PostoRebounds', 'PostdRebounds',\n",
       "       'PostRebounds', 'PostAssists', 'PostSteals', 'PostBlocks',\n",
       "       'PostTurnovers', 'PostPF', 'PostDQ', 'career_year', 'ft%', 'fg%',\n",
       "       'three%', 'gs%', 'Postft%', 'Postfg%', 'Postthree%', 'Postgs%', 'efg%',\n",
       "       'ts%', 'ppg', 'rpg', 'apg', 'spg', 'bpg', 'eff', 'pp36',\n",
       "       'defensive_prowess', 'defensive_discipline', 'mpg', 'pos', 'college',\n",
       "       'playoff', 'confID', 'playoff_progression', 'height', 'weight',\n",
       "       'award_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['playerID', 'year', 'stint', 'tmID', 'height', 'weight', 'pos',\n",
       "       'college', 'confID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competition.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['ft%','fg%','three%','gs%',\n",
    "              #'Postft%','Postfg%','Postthree%','Postgs%', #postseason\n",
    "              'efg%','ts%',\n",
    "              'ppg','rpg','apg','spg','bpg','eff', 'pp36',\n",
    "              'defensive_prowess','defensive_discipline',\n",
    "              'mpg','award_count']\n",
    "\n",
    "# The output columns are the genres\n",
    "output_cols = 'playoff'\n",
    "\n",
    "known_columns = ['playerID', 'year', 'stint', 'tmID', 'height', 'weight', 'pos','college', 'confID']\n",
    "\n",
    "# Averages to calculate for precision, recall, and f1-score\n",
    "averages = [None, \"macro\", \"weighted\", \"micro\", \"samples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerID</th>\n",
       "      <th>year</th>\n",
       "      <th>stint</th>\n",
       "      <th>tmID</th>\n",
       "      <th>GP</th>\n",
       "      <th>oRebounds</th>\n",
       "      <th>dRebounds</th>\n",
       "      <th>dq</th>\n",
       "      <th>PostMinutes</th>\n",
       "      <th>PostPoints</th>\n",
       "      <th>PostoRebounds</th>\n",
       "      <th>PostdRebounds</th>\n",
       "      <th>PostRebounds</th>\n",
       "      <th>PostAssists</th>\n",
       "      <th>PostSteals</th>\n",
       "      <th>PostBlocks</th>\n",
       "      <th>PostTurnovers</th>\n",
       "      <th>PostPF</th>\n",
       "      <th>PostDQ</th>\n",
       "      <th>career_year</th>\n",
       "      <th>ft%</th>\n",
       "      <th>fg%</th>\n",
       "      <th>three%</th>\n",
       "      <th>gs%</th>\n",
       "      <th>Postft%</th>\n",
       "      <th>Postfg%</th>\n",
       "      <th>Postthree%</th>\n",
       "      <th>Postgs%</th>\n",
       "      <th>efg%</th>\n",
       "      <th>ts%</th>\n",
       "      <th>ppg</th>\n",
       "      <th>rpg</th>\n",
       "      <th>apg</th>\n",
       "      <th>spg</th>\n",
       "      <th>bpg</th>\n",
       "      <th>eff</th>\n",
       "      <th>pp36</th>\n",
       "      <th>defensive_prowess</th>\n",
       "      <th>defensive_discipline</th>\n",
       "      <th>mpg</th>\n",
       "      <th>pos</th>\n",
       "      <th>college</th>\n",
       "      <th>playoff</th>\n",
       "      <th>confID</th>\n",
       "      <th>playoff_progression</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>award_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>555</td>\n",
       "      <td>26</td>\n",
       "      <td>1.65</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.98</td>\n",
       "      <td>13.19</td>\n",
       "      <td>6.69</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-276.11</td>\n",
       "      <td>14.76</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11.92</td>\n",
       "      <td>32.54</td>\n",
       "      <td>2</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>555</td>\n",
       "      <td>27</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.86</td>\n",
       "      <td>11.63</td>\n",
       "      <td>5.41</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-327.81</td>\n",
       "      <td>14.04</td>\n",
       "      <td>56.7</td>\n",
       "      <td>12.22</td>\n",
       "      <td>29.81</td>\n",
       "      <td>2</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>555</td>\n",
       "      <td>30</td>\n",
       "      <td>1.47</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.67</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>10.60</td>\n",
       "      <td>4.70</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-272.13</td>\n",
       "      <td>14.40</td>\n",
       "      <td>50.7</td>\n",
       "      <td>11.26</td>\n",
       "      <td>26.40</td>\n",
       "      <td>2</td>\n",
       "      <td>575</td>\n",
       "      <td>1</td>\n",
       "      <td>701</td>\n",
       "      <td>1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>555</td>\n",
       "      <td>22</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.5</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>6.64</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-137.50</td>\n",
       "      <td>11.52</td>\n",
       "      <td>40.5</td>\n",
       "      <td>7.72</td>\n",
       "      <td>21.00</td>\n",
       "      <td>2</td>\n",
       "      <td>575</td>\n",
       "      <td>1</td>\n",
       "      <td>701</td>\n",
       "      <td>1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>555</td>\n",
       "      <td>31</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9.81</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-250.06</td>\n",
       "      <td>14.04</td>\n",
       "      <td>42.6</td>\n",
       "      <td>10.70</td>\n",
       "      <td>25.06</td>\n",
       "      <td>2</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playerID  year  stint  tmID  GP  oRebounds  dRebounds    dq  PostMinutes  \\\n",
       "0         0     2      0   555  26       1.65       5.04  0.08          0.0   \n",
       "1         0     3      0   555  27       1.67       3.74  0.00          0.0   \n",
       "2         0     4      0   555  30       1.47       3.23  0.00         23.0   \n",
       "3         0     5      0   555  22       0.77       2.59  0.00         33.5   \n",
       "4         0     6      0   555  31       0.94       2.52  0.00          0.0   \n",
       "\n",
       "   PostPoints  PostoRebounds  PostdRebounds  PostRebounds  PostAssists  \\\n",
       "0        0.00           0.00           0.00          0.00         0.00   \n",
       "1        0.00           0.00           0.00          0.00         0.00   \n",
       "2        7.67           0.33           1.33          1.67         1.33   \n",
       "3       10.00           1.50           3.00          4.50         1.50   \n",
       "4        0.00           0.00           0.00          0.00         0.00   \n",
       "\n",
       "   PostSteals  PostBlocks  PostTurnovers  PostPF  PostDQ  career_year   ft%  \\\n",
       "0        0.00        0.00           0.00    0.00     0.0            1  0.73   \n",
       "1        0.00        0.00           0.00    0.00     0.0            2  0.48   \n",
       "2        1.33        0.33           2.67    2.67     0.0            3  0.70   \n",
       "3        0.50        1.00           1.50    3.50     0.0            4  0.61   \n",
       "4        0.00        0.00           0.00    0.00     0.0            5  0.73   \n",
       "\n",
       "    fg%  three%   gs%  Postft%  Postfg%  Postthree%  Postgs%  efg%   ts%  \\\n",
       "0  0.39    0.25  0.88      0.0     0.00        0.00      0.0  0.84  0.98   \n",
       "1  0.38    0.33  1.00      0.0     0.00        0.00      0.0  0.82  0.86   \n",
       "2  0.39    0.30  0.83      1.0     0.27        0.43      1.0  0.88  0.96   \n",
       "3  0.35    0.38  0.50      0.5     0.35        0.25      1.0  0.84  0.92   \n",
       "4  0.39    0.40  1.00      0.0     0.00        0.00      0.0  0.90  0.98   \n",
       "\n",
       "     ppg   rpg   apg   spg   bpg     eff   pp36  defensive_prowess  \\\n",
       "0  13.19  6.69  2.04  1.62  0.35 -276.11  14.76               70.0   \n",
       "1  11.63  5.41  2.22  1.56  0.37 -327.81  14.04               56.7   \n",
       "2  10.60  4.70  2.73  1.47  0.37 -272.13  14.40               50.7   \n",
       "3   6.64  3.36  2.05  1.36  0.09 -137.50  11.52               40.5   \n",
       "4   9.81  3.45  1.94  1.55  0.19 -250.06  14.04               42.6   \n",
       "\n",
       "   defensive_discipline    mpg  pos  college  playoff  confID  \\\n",
       "0                 11.92  32.54    2      575        0     701   \n",
       "1                 12.22  29.81    2      575        0     701   \n",
       "2                 11.26  26.40    2      575        1     701   \n",
       "3                  7.72  21.00    2      575        1     701   \n",
       "4                 10.70  25.06    2      575        0     701   \n",
       "\n",
       "   playoff_progression  height  weight  award_count  \n",
       "0                    0    74.0     169            0  \n",
       "1                    0    74.0     169            0  \n",
       "2                    1    74.0     169            0  \n",
       "3                    1    74.0     169            0  \n",
       "4                    0    74.0     169            0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "playerID               False\n",
       "year                   False\n",
       "stint                  False\n",
       "tmID                   False\n",
       "GP                     False\n",
       "                       ...  \n",
       "confID                 False\n",
       "playoff_progression    False\n",
       "height                 False\n",
       "weight                 False\n",
       "award_count            False\n",
       "Length: 48, dtype: bool"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "def plot_learning_curve(\n",
    "    title,\n",
    "    train_sizes, \n",
    "    train_scores, \n",
    "    test_scores, \n",
    "    fit_times,\n",
    "    score_times,\n",
    "    axes=None,\n",
    "    ylim=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator instance\n",
    "        An estimator instance implementing `fit` and `predict` methods which\n",
    "        will be cloned for each validation.\n",
    "\n",
    "    title : str\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like of shape (n_samples, n_features)\n",
    "        Training vector, where ``n_samples`` is the number of samples and\n",
    "        ``n_features`` is the number of features.\n",
    "\n",
    "    y : array-like of shape (n_samples) or (n_samples, n_features)\n",
    "        Target relative to ``X`` for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array-like of shape (3,), default=None\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple of shape (2,), default=None\n",
    "        Defines minimum and maximum y-values plotted, e.g. (ymin, ymax).\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, default=None\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, default=None\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like of shape (n_ticks,)\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the ``dtype`` is float, it is regarded\n",
    "        as a fraction of the maximum size of the training set (that is\n",
    "        determined by the selected validation method), i.e. it has to be within\n",
    "        (0, 1]. Otherwise it is interpreted as absolute sizes of the training\n",
    "        sets. Note that for classification the number of samples usually have\n",
    "        to be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "    axes = axes.reshape(-1)\n",
    "    fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "    fig = fig.delaxes(axes[-1])\n",
    "    \n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "    score_times_mean = np.mean(score_times, axis=1)\n",
    "    score_times_std = np.std(score_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"g\",\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\"\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\"\n",
    "    )\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, \"o-\")\n",
    "    axes[1].fill_between(\n",
    "        train_sizes,\n",
    "        fit_times_mean - fit_times_std,\n",
    "        fit_times_mean + fit_times_std,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    fit_time_argsort = fit_times_mean.argsort()\n",
    "    fit_time_sorted = fit_times_mean[fit_time_argsort]\n",
    "    test_scores_mean_sorted = test_scores_mean[fit_time_argsort]\n",
    "    test_scores_std_sorted = test_scores_std[fit_time_argsort]\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_time_sorted, test_scores_mean_sorted, \"o-\")\n",
    "    axes[2].fill_between(\n",
    "        fit_time_sorted,\n",
    "        test_scores_mean_sorted - test_scores_std_sorted,\n",
    "        test_scores_mean_sorted + test_scores_std_sorted,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    # Plot n_samples vs score_times\n",
    "    axes[3].grid()\n",
    "    axes[3].plot(train_sizes, score_times_mean, \"o-\")\n",
    "    axes[3].fill_between(\n",
    "        train_sizes,\n",
    "        score_times_mean - score_times_std,\n",
    "        score_times_mean + score_times_std,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[3].set_xlabel(\"Training examples\")\n",
    "    axes[3].set_ylabel(\"score_times\")\n",
    "    axes[3].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot score_time vs score\n",
    "    score_time_argsort = score_times_mean.argsort()\n",
    "    score_time_sorted = score_times_mean[score_time_argsort]\n",
    "    test_scores_mean_sorted = test_scores_mean[score_time_argsort]\n",
    "    test_scores_std_sorted = test_scores_std[score_time_argsort]\n",
    "    axes[4].grid()\n",
    "    axes[4].plot(score_time_sorted, test_scores_mean_sorted, \"o-\")\n",
    "    axes[4].fill_between(\n",
    "        score_time_sorted,\n",
    "        test_scores_mean_sorted - test_scores_std_sorted,\n",
    "        test_scores_mean_sorted + test_scores_std_sorted,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[4].set_xlabel(\"score_times\")\n",
    "    axes[4].set_ylabel(\"Score\")\n",
    "    axes[4].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "#loop in rolling window method through all data\n",
    "unique_years = data['year'].unique()\n",
    "#sort the years\n",
    "unique_years.sort()\n",
    "rolling_window_results = []\n",
    "trained_models = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_to_remove():\n",
    "    return ['playoff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "toZeroArr = ['GP', 'oRebounds', 'dRebounds', 'dq', 'PostMinutes',\n",
    "   'PostPoints', 'PostoRebounds', 'PostdRebounds', 'PostRebounds',\n",
    "   'PostAssists', 'PostSteals', 'PostBlocks', 'PostTurnovers', 'PostPF',\n",
    "   'PostDQ', 'career_year', 'ft%', 'fg%', 'three%', 'gs%', 'Postft%',\n",
    "   'Postfg%', 'Postthree%', 'Postgs%', 'efg%', 'ts%', 'ppg', 'rpg', 'apg',\n",
    "   'spg', 'bpg', 'eff', 'pp36', 'defensive_prowess',\n",
    "   'defensive_discipline', 'mpg','playoff_progression', 'award_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data, unique_years, i):\n",
    "    train_years_before = unique_years[:i]\n",
    "    train_years = unique_years[:i+1]\n",
    "    test_year = unique_years[i]\n",
    "\n",
    "    if i + 1 > len(unique_years): \n",
    "        return\n",
    "\n",
    "    predict_year = unique_years[i+1]  # Predicting for year i+2 \n",
    "\n",
    "    if predict_year < test_year:\n",
    "        return\n",
    "\n",
    "\n",
    "    train_before = data[data['year'].isin(train_years_before)]\n",
    "    train = data[data['year'].isin(train_years)]\n",
    "    test = data[data['year'] == test_year]\n",
    "    actual = data[data['year'] == predict_year]\n",
    "\n",
    "    return train_before, train, test, actual, predict_year, train_years, test_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_data(train_before, train, test, actual, data, unique_years):\n",
    "    #one hot encoding\n",
    "    # train_before = pd.get_dummies(train_before, columns=['tmID', 'confID', 'pos', 'college', 'playerID'])\n",
    "    # train = pd.get_dummies(train, columns=['tmID', 'confID', 'pos', 'college', 'playerID']) \n",
    "    # Removing and adding rows based on certain conditions\n",
    "    train_before_indices_to_remove = []\n",
    "    train_indices_to_remove = []\n",
    "    #check if a player have a entry in the train df with the next year\n",
    "    for index, row in train_before.iterrows():\n",
    "        player_id = row['playerID']\n",
    "        year = row['year'] + 1 \n",
    "        if row['stint'] > 1:\n",
    "            train_before_indices_to_remove.append(index)\n",
    "        elif not (((train['playerID'] == player_id) & (train['year'] == year)).any()):\n",
    "            data_to_add = {\n",
    "                'playerID': player_id, \n",
    "                'year': year,        \n",
    "            }\n",
    "            new_row = pd.DataFrame(data_to_add, index=[0])\n",
    "            train = pd.concat([train, new_row], ignore_index=True)\n",
    "       \n",
    "\n",
    "    train_before = train_before.drop(train_before_indices_to_remove)\n",
    "    for index, row in train.iterrows():\n",
    "        player_id = row['playerID']\n",
    "        year = row['year'] - 1 \n",
    "        if row['stint'] > 1:\n",
    "            train_indices_to_remove.append(index)\n",
    "        elif not (((train_before['playerID'] == player_id) & (train_before['year'] == year)).any()):\n",
    "            data_to_add = {\n",
    "                'playerID': player_id, \n",
    "                'year': year,        \n",
    "            }\n",
    "            new_row = pd.DataFrame(data_to_add, index=[0])\n",
    "            train_before = pd.concat([train_before , new_row], ignore_index=True)\n",
    "\n",
    "    train = train_before.drop(train_indices_to_remove)\n",
    "    train.fillna(0, inplace=True)\n",
    "    train.sort_values(by='playerID', inplace=True)\n",
    "    train_before.fillna(0, inplace=True)\n",
    "    train_before.sort_values(by='playerID', inplace=True)\n",
    "    remove_columns = get_columns_to_remove()\n",
    "    actual[toZeroArr] = 0\n",
    "\n",
    "\n",
    "\n",
    "    X_train = train.drop(remove_columns, axis=1)\n",
    "    y_train = train['playoff']\n",
    "    X_actual = actual.drop(remove_columns, axis=1)\n",
    "    y_actual = actual['playoff']\n",
    "\n",
    "    # Ensure that 'X_actual' has the same features as 'X_train'\n",
    "    X_actual = actual[X_train.columns]\n",
    "\n",
    "    return X_train, y_train, X_actual, y_actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_evaluate_model(X_train, y_train, model):\n",
    "    classifier = model.fit(X_train, y_train)\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_and_evaluate(classifier, X_actual, y_actual):\n",
    "    # Evaluate the model\n",
    "    predictions = classifier.predict(X_actual)\n",
    "    predictions_prob = classifier.predict_proba(X_actual)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_actual, predictions)\n",
    "    auc_score = roc_auc_score(y_actual, predictions_prob)\n",
    "\n",
    "    return accuracy, auc_score, predictions, predictions_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rolling_window_method(i, model, data, unique_years):\n",
    "    train_before, train, test, actual, predict_year, train_years, test_year = prepare_training_data(data, unique_years, i)\n",
    "    \n",
    "    if train_before is None:\n",
    "        return None\n",
    "\n",
    "    X_train, y_train, X_actual, y_actual= process_data(train_before, train, test, actual, data, unique_years)\n",
    "\n",
    "    #create a csv file for each year, storing the data for that year and that model, in the folder output/rolling_window\n",
    "    X_train.to_csv(f'output/rolling_window/{model.__class__.__name__}_{test_year}_train.csv', index=False)\n",
    "    #X_test.to_csv(f'output/rolling_window/{model.__class__.__name__}_{test_year}_test.csv', index=False)\n",
    "    X_actual.to_csv(f'output/rolling_window/{model.__class__.__name__}_{test_year}_actual.csv', index=False)\n",
    "    # y_actual.to_csv(f'output/rolling_window/{model.__class__.__name__}_{test_year}_y_actual.csv', index=False)\n",
    "\n",
    "\n",
    "    classifier = train_and_evaluate_model(X_train, y_train, model)\n",
    "\n",
    "    # Calculate accuracy\n",
    "\n",
    "    accuracy, auc_score, predictions, predictions_prob = predict_and_evaluate(classifier, X_actual, y_actual)\n",
    "\n",
    "    #print(f\"Best params for {model.__class__.__name__}: {model.best_params_}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"AUC: {auc_score:.4f}\")\n",
    "\n",
    "\n",
    "    return {\n",
    "        'train_years': train_years,\n",
    "        'test_year': test_year,\n",
    "        'Year': predict_year,\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc_score,\n",
    "        'model': classifier\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_training_loop(model, data, unique_years):\n",
    "    rolling_window_results = []\n",
    "    for i in range(1,len(unique_years) - 1):\n",
    "        result = rolling_window_method(i, model, data, unique_years)\n",
    "        if result:\n",
    "            rolling_window_results.append(result)\n",
    "    return rolling_window_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5139\n",
      "AUC: 0.5000\n",
      "Accuracy: 0.4749\n",
      "AUC: 0.5046\n",
      "Accuracy: 0.4036\n",
      "AUC: 0.4976\n",
      "Accuracy: 0.3955\n",
      "AUC: 0.4930\n",
      "Accuracy: 0.4413\n",
      "AUC: 0.5020\n",
      "Accuracy: 0.4211\n",
      "AUC: 0.5050\n",
      "Accuracy: 0.4308\n",
      "AUC: 0.4941\n",
      "Accuracy: 0.3913\n",
      "AUC: 0.5051\n"
     ]
    }
   ],
   "source": [
    "rolling_window_results += model_training_loop(model, data, unique_years)\n",
    "trained_models.append(rolling_window_results[-1]['model'])  # Get the last trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5139\n",
      "AUC: 0.6018\n",
      "Accuracy: 0.4693\n",
      "AUC: 0.4968\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m rolling_window_results \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model_training_loop(model, data, unique_years)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trained_models\u001b[39m.\u001b[39mappend(rolling_window_results[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m])  \u001b[39m# Get the last trained model\u001b[39;00m\n",
      "\u001b[1;32m/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m rolling_window_results \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39mlen\u001b[39m(unique_years) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     result \u001b[39m=\u001b[39m rolling_window_method(i, model, data, unique_years)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         rolling_window_results\u001b[39m.\u001b[39mappend(result)\n",
      "\u001b[1;32m/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb Cell 19\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m train_before \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m X_train, y_train, X_actual, y_actual\u001b[39m=\u001b[39m process_data(train_before, train, test, actual, data, unique_years)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#create a csv file for each year, storing the data for that year and that model, in the folder output/rolling_window\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m X_train\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39moutput/rolling_window/\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtest_year\u001b[39m}\u001b[39;00m\u001b[39m_train.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         data_to_add \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mplayerID\u001b[39m\u001b[39m'\u001b[39m: player_id, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m: year,        \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         }\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         new_row \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data_to_add, index\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         train_before \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([train_before , new_row], ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m train \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39mdrop(train_indices_to_remove)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juanbellon/Documents/feup/ac/src/6-predictive.ipynb#X36sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m train\u001b[39m.\u001b[39mfillna(\u001b[39m0\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/concat.py:393\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    378\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    380\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[0;32m--> 393\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/concat.py:667\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjs:\n\u001b[1;32m    666\u001b[0m     indexers \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 667\u001b[0m     \u001b[39mfor\u001b[39;00m ax, new_labels \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes):\n\u001b[1;32m    668\u001b[0m         \u001b[39m# ::-1 to convert BlockManager ax to DataFrame ax\u001b[39;00m\n\u001b[1;32m    669\u001b[0m         \u001b[39mif\u001b[39;00m ax \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbm_axis:\n\u001b[1;32m    670\u001b[0m             \u001b[39m# Suppress reindexing on concat axis\u001b[39;00m\n\u001b[1;32m    671\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/concat.py:698\u001b[0m, in \u001b[0;36m_Concatenator.new_axes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[39m@cache_readonly\u001b[39m\n\u001b[1;32m    696\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_axes\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Index]:\n\u001b[1;32m    697\u001b[0m     ndim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_result_dim()\n\u001b[0;32m--> 698\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    699\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concat_axis \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbm_axis \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_comb_axis(i)\n\u001b[1;32m    700\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(ndim)\n\u001b[1;32m    701\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/concat.py:699\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[39m@cache_readonly\u001b[39m\n\u001b[1;32m    696\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_axes\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Index]:\n\u001b[1;32m    697\u001b[0m     ndim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_result_dim()\n\u001b[1;32m    698\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m--> 699\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concat_axis \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbm_axis \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_comb_axis(i)\n\u001b[1;32m    700\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(ndim)\n\u001b[1;32m    701\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/concat.py:705\u001b[0m, in \u001b[0;36m_Concatenator._get_comb_axis\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_comb_axis\u001b[39m(\u001b[39mself\u001b[39m, i: AxisInt) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Index:\n\u001b[1;32m    704\u001b[0m     data_axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_get_block_manager_axis(i)\n\u001b[0;32m--> 705\u001b[0m     \u001b[39mreturn\u001b[39;00m get_objs_combined_axis(\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobjs,\n\u001b[1;32m    707\u001b[0m         axis\u001b[39m=\u001b[39;49mdata_axis,\n\u001b[1;32m    708\u001b[0m         intersect\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintersect,\n\u001b[1;32m    709\u001b[0m         sort\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msort,\n\u001b[1;32m    710\u001b[0m         copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy,\n\u001b[1;32m    711\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/api.py:103\u001b[0m, in \u001b[0;36mget_objs_combined_axis\u001b[0;34m(objs, intersect, axis, sort, copy)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39mExtract combined index: return intersection or union (depending on the\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mvalue of \"intersect\") of indexes on given axis, or None if all objects\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mIndex\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m obs_idxes \u001b[39m=\u001b[39m [obj\u001b[39m.\u001b[39m_get_axis(axis) \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m objs]\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m _get_combined_index(obs_idxes, intersect\u001b[39m=\u001b[39;49mintersect, sort\u001b[39m=\u001b[39;49msort, copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/api.py:156\u001b[0m, in \u001b[0;36m_get_combined_index\u001b[0;34m(indexes, intersect, sort, copy)\u001b[0m\n\u001b[1;32m    154\u001b[0m         index \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39mintersection(other)\n\u001b[1;32m    155\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     index \u001b[39m=\u001b[39m union_indexes(indexes, sort\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    157\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m sort:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/api.py:312\u001b[0m, in \u001b[0;36munion_indexes\u001b[0;34m(indexes, sort)\u001b[0m\n\u001b[1;32m    310\u001b[0m index \u001b[39m=\u001b[39m indexes[\u001b[39m0\u001b[39m]\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(index\u001b[39m.\u001b[39mequals(other) \u001b[39mfor\u001b[39;00m other \u001b[39min\u001b[39;00m indexes[\u001b[39m1\u001b[39m:]):\n\u001b[0;32m--> 312\u001b[0m     index \u001b[39m=\u001b[39m _unique_indices(indexes, dtype)\n\u001b[1;32m    314\u001b[0m name \u001b[39m=\u001b[39m get_unanimous_names(\u001b[39m*\u001b[39mindexes)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    315\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m!=\u001b[39m index\u001b[39m.\u001b[39mname:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/api.py:242\u001b[0m, in \u001b[0;36munion_indexes.<locals>._unique_indices\u001b[0;34m(inds, dtype)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[39mConcatenate indices and remove duplicates.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39mIndex\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(ind, Index) \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m inds):\n\u001b[0;32m--> 242\u001b[0m     result \u001b[39m=\u001b[39m inds[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mappend(inds[\u001b[39m1\u001b[39;49m:])\u001b[39m.\u001b[39;49munique()\n\u001b[1;32m    243\u001b[0m     result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    244\u001b[0m     \u001b[39mif\u001b[39;00m sort:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3048\u001b[0m, in \u001b[0;36mIndex.unique\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   3045\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_view()\n\u001b[1;32m   3047\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39munique()\n\u001b[0;32m-> 3048\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shallow_copy(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:770\u001b[0m, in \u001b[0;36mIndex._shallow_copy\u001b[0;34m(self, values, name)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \u001b[39mCreate a new Index with the same class as the caller, don't copy the\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[39mdata, use the same object attributes with passed in attributes taking\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[39mname : Label, defaults to self.name\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    768\u001b[0m name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m no_default \u001b[39melse\u001b[39;00m name\n\u001b[0;32m--> 770\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_simple_new(values, name\u001b[39m=\u001b[39;49mname, refs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_references)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:669\u001b[0m, in \u001b[0;36mIndex._simple_new\u001b[0;34m(cls, values, name, refs)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     result\u001b[39m.\u001b[39m_references \u001b[39m=\u001b[39m BlockValuesRefs()\n\u001b[0;32m--> 669\u001b[0m result\u001b[39m.\u001b[39;49m_references\u001b[39m.\u001b[39;49madd_index_reference(result)\n\u001b[1;32m    671\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "rolling_window_results += model_training_loop(model, data, unique_years)\n",
    "trained_models.append(rolling_window_results[-1]['model'])  # Get the last trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "rolling_window_results += model_training_loop(model, data, unique_years)\n",
    "trained_models.append(rolling_window_results[-1]['model'])  # Get the last trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian naive bayes\n",
    "model = GaussianNB()\n",
    "rolling_window_results += model_training_loop(model, data, unique_years)\n",
    "trained_models.append(rolling_window_results[-1]['model'])  # Get the last trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "model = LogisticRegression()\n",
    "rolling_window_results += model_training_loop(model, data, unique_years)\n",
    "trained_models.append(rolling_window_results[-1]['model'])  # Get the last trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ada boost\n",
    "model = AdaBoostClassifier()\n",
    "rolling_window_results += model_training_loop(model, data, unique_years)\n",
    "trained_models.append(rolling_window_results[-1]['model'])  # Get the last trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level0 = list()\n",
    "#append models in trained_models to level0\n",
    "for i in range(len(trained_models)):\n",
    "    level0.append((str(i), trained_models[i]))\n",
    "\n",
    "level1 = RandomForestClassifier(n_estimators=100, min_samples_split=3, min_samples_leaf=2, max_features='sqrt', max_depth=9, bootstrap=True, criterion='entropy', random_state=42)\n",
    "clf = StackingClassifier(estimators=level0, final_estimator=level1, cv=4)\n",
    "\n",
    "rolling_window_results += model_training_loop(clf, data, unique_years)\n",
    "trained_models.append(rolling_window_results[-1]['model'])  # Get the last trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add all the columns in data to comp data and fill the null values with 0\n",
    "comp_columns = ['year', 'stint', 'GP', 'oRebounds', 'dRebounds', 'dq', 'PostMinutes',\n",
    "       'PostPoints', 'PostoRebounds', 'PostdRebounds', 'PostRebounds',\n",
    "       'PostAssists', 'PostSteals', 'PostBlocks', 'PostTurnovers', 'PostPF',\n",
    "       'PostDQ', 'career_year', 'ft%', 'fg%', 'three%', 'gs%', 'Postft%',\n",
    "       'Postfg%', 'Postthree%', 'Postgs%', 'efg%', 'ts%', 'ppg', 'rpg', 'apg',\n",
    "       'spg', 'bpg', 'eff', 'pp36', 'defensive_prowess',\n",
    "       'defensive_discipline', 'mpg', 'pos', 'college', 'playoff_progression',\n",
    "       'height', 'weight', 'award_count']\n",
    "\n",
    "competition = competition.reindex(columns=comp_columns, fill_value=0)\n",
    "\n",
    "\n",
    "def predict_comp():\n",
    "    for i in range(len(trained_models)):\n",
    "        clf = trained_models[i]\n",
    "        predictions = clf.predict_proba(competition.values)[:, 1]\n",
    "        competition[f'pred_{i}'] = predictions\n",
    "    return competition\n",
    "\n",
    "print(predict_comp())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
